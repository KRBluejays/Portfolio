# 한국어 언어 모델 벤치마크 평가 가이드

## 📋 목차

1. [전문 지식 평가](#1-전문-지식-평가)
2. [상식 및 추론 능력 평가](#2-상식-및-추론-능력-평가)
3. [수학적 추론 능력 평가](#3-수학적-추론-능력-평가)
4. [감성 지능 평가](#4-감성-지능-평가)
5. [지시 수행 능력 평가](#5-지시-수행-능력-평가)
6. [한국 특화 평가](#6-한국-특화-평가)
7. [윤리적 측면 평가](#7-윤리적-측면-평가)
8. [유용성 평가](#8-유용성-평가)

---

## 1. 전문 지식 평가 

### 📚 Ko-GPQA (Korean Graduate-level Proof Q&A)

#### 개요
Ko-GPQA는 대학원 수준의 전문가들이 작성한 영어 내용을 Flito가 번역한 한국어 질문-답변 데이터셋입니다. 이 데이터셋은 전문가의 깊이 있는 지식이 필요한 문제들로 구성되어 있으며, 일반인들이 인터넷 검색을 통해서도 쉽게 답을 찾을 수 없도록 설계되었습니다.

#### 주요 특징
- **🎓 높은 난이도**: 해당 분야 전문가(PhD 소지자 또는 과정생)만이 풀 수 있는 수준
- **🔍 검색 저항성**: 일반적인 인터넷 검색으로는 답을 찾기 어려움 
- **✅ 객관성**: 각 문제는 명확한 정답이 있는 객관식 문제
- **🧪 전문 분야**: 생물학, 물리학, 화학 등 자연과학 분야 중심
- **👥 검증 과정**: 2명의 전문가 검증과 3명의 비전문가 검증을 거침

#### 데이터셋 구조
- 총 448개의 메인 문항
- 각 문항은 4지선다형
- 각 문제당 상세한 설명과 정답 근거 포함

#### 예시 문제

##### 💊 화학 분야
```
Q: 메틸사이클로펜타디엔을 메틸 이소아밀 케톤과 피롤리딘 촉매 존재 하에서 반응시켰을 때, 
밝은 노란색의 교차공액 폴리알켄일 탄화수소 생성물이 물과 함께 부산물로 생성되었습니다. 
이 생성물은 풀벤의 유도체입니다. 이후 이 생성물을 에틸 아크릴레이트와 1:1 비율로 
반응시켰을 때 밝은 노란색이 사라졌습니다. 최종 생성물의 화학적으로 구별되는 이성질체의 
수는 몇 개입니까? (입체이성질체는 제외)

A) 2
B) 16
C) 8
D) 4

정답: B
```

##### ⚛️ 물리학 분야
```
Q: 질량 m인 입자가 등방성 3차원 포텐셜 V(r) = 1/2mω²r²에서 운동하고 있습니다. 
여기서 ω는 진동의 각진동수이고 r은 구면좌표계에서 입자의 원점으로부터의 방사 거리입니다. 
세 번째 들뜬 상태의 에너지값과 동일한 에너지 고유값을 가질 수 있는 선형 독립적인 
고유함수의 개수는 각각 얼마입니까?

A) 11π²ℏ²/(2mr²), 3
B) (9/2)ℏω, 10
C) 11π²ℏ²/(2mr²), 10
D) (9/2)ℏω, 3

정답: B
```

#### 📊 평가 지표
| 구분 | 정확도 |
|------|---------|
| 전문가 | 약 65% |
| 비전문가 | 약 34% |
| GPT-4 | 약 39% |

#### ⚠️ 한계점
- 데이터셋의 크기가 상대적으로 작음
- 특정 전문 분야에 한정됨
- 높은 제작 비용과 시간이 필요
- 전문가 검증 과정의 복잡성

---

## 2. 상식 및 추론 능력 평가

### 🧩 Ko-WinoGrande

#### 개요
WinoGrande는 상식적 추론 능력을 평가하기 위한 대규모 데이터셋으로, 기존 Winograd Schema Challenge(WSC)를 확장한 버전입니다. 전문가가 직접 제작한 273개의 WSC 문제와 달리, WinoGrande는 43,972개의 문제로 구성되어 있으며 크라우드소싱을 통해 수집되었습니다.

#### 주요 특징
- 대규모 데이터셋: 약 44,000개의 문제
- 편향성 제거: AFLITE 알고리즘을 통한 데이터셋 편향 감소
- 검증된 품질: 전문가 검증과 비전문가 검증을 통한 품질 관리

#### 데이터 수집 과정
1. **초기 수집**: 77k 문제(38k twins) 크라우드소싱
2. **검증 단계**: 68% 통과하여 53k 문제로 감소
3. **AFLITE 적용**: 최종 43,972개로 정제

#### 데이터셋 구조

##### WINOGRANDE_debiased (편향 제거된 핵심 데이터셋)
총 12,282개
- 학습: 9,248개
- 개발: 1,267개
- 평가: 1,767개

##### WINOGRANDE_all (전체 데이터셋)
총 43,972개
- 학습: 40,938개
- 개발: 1,267개
- 평가: 1,767개

#### 예시 문제
WinoGrande는 문장 내 대명사나 지시어가 무엇을 가리키는지 파악하는 상식 추론 문제들로 구성되어 있습니다. 각 문제는 두 개의 선택지 중 하나를 고르는 형식입니다.
##### 🤝 사회적 상식 문제
```
Q: Craig는 청소하는 것을 매우 좋아하지만 Derrick은 그렇지 않은데, 
그 이유는 _가 매우 깔끔하기 때문이다.

선택지:
1) Craig
2) Derrick

정답: 1
설명: 청소를 좋아하는 성향과 깔끔한 성격 사이의 관계를 파악하는 문제입니다.
```

##### 🔄 인과관계 추론 문제
```
Q: Megan은 Jessica보다 돈이 훨씬 더 많은데, 
그 이유는 _가 방금 당첨 복권을 샀기 때문이다.

선택지:
1) Megan
2) Jessica

정답: 1
설명: 돈이 많다는 결과와 복권 당첨이라는 원인 사이의 관계를 파악하는 문제입니다.
```

##### 🏗️ 물리적 상식 문제
```
Q: 금고 직원들이 수레에서 금괴를 꺼내 _가 가득 찰 때까지 쌓았다.

선택지:
1) 금고
2) 수레

정답: 1
설명: 물건을 옮기는 상황에서 '가득 찰 때까지 쌓는' 대상이 무엇인지 파악하는 문제입니다.
```

##### 🍬 선호도 추론 문제
```
Q: 나는 간식으로 땅콩과 건포도를 한 봉지 집었다. 더 달콤한 간식을 원해서 일단 _를 먹었다.

선택지:
1) 건포도
2) 땅콩

정답: 1
설명: '더 달콤한' 이라는 조건과 두 식품의 특성을 연관 지어 추론하는 문제입니다.
```
이러한 예시들은 단순한 문법적 이해를 넘어서 문맥과 상식적 추론을 필요로 합니다. 특히 각 문제는 언어 모델이 단순히 단어 연관성이나 통계적 패턴에 의존하지 않고, 실제 상황에 대한 이해를 바탕으로 추론할 수 있는지를 평가합니다.

#### 📊 평가 지표

##### 성능 비교
| 모델/평가자 | 정확도 |
|------------|--------|
| 인간 평균 | 94.0% |
| RoBERTa | 79.1% |
| BERT | 64.9% |
| WKH | 49.6% |
| Ensemble LMs | 50.9% |

## 3. 수학적 추론 능력 평가
### 📝 Ko-GSM8K
#### 개요
GSM8K(Grade School Math 8K)는 초등학교 수준의 수학 문장제 문제 8.5K개로 구성된 데이터셋입니다. 이 데이터셋은 복잡한 수학적 개념보다는 기본적인 산술 연산을 통한 다단계 추론 능력을 평가하는 것에 중점을 두고 있습니다.

#### 주요 특징
- 🔢 다단계 풀이: 2-8단계의 풀이 과정이 필요한 문제들로 구성
- ✍️ 자연어 설명: 수식뿐만 아니라 자연어로 된 상세한 풀이 과정 포함
- 🎯 높은 다양성: 비슷한 템플릿이나 표면적인 차이만 있는 문제들을 피하고 각각 독특한 문제 상황 제시
- 📚 적절한 난이도: 중학생 수준에서 풀 수 있는 난이도로 설계

#### 데이터셋 구조
- 총 8.5K개의 문제
  - 훈련셋: 7.5K개
  - 테스트셋: 1K개
- 각 문제는 문제 설명, 자연어 풀이 과정, 최종 답안으로 구성

#### 예시 문제
```
Q: Beth는 일주일에 4, 2 다스의 쿠키를 굽습니다. 이 쿠키들을 16명이 동등하게 나누어 먹는다면, 각 사람은 몇 개의 쿠키를 먹게 되나요?

풀이:
1. Beth가 4, 2다스의 쿠키를 굽습니다. 4*2 = 8 다스의 쿠키
2. 1다스는 12개이므로, 8다스는 12*8 = 96개의 쿠키
3. 96개의 쿠키를 16명이 나누어 먹으므로 96/16 = 6개의 쿠키

답: 6
```
```
Q: Mrs. Lim은 하루에 두 번 소를 착유합니다. 어제 아침에는 68갤런의 우유를 얻었고, 저녁에는 82갤런을 얻었습니다. 오늘 아침에는 어제 아침보다 18갤런 적게 얻었습니다. 오후에 우유를 일부 판매한 후, Mrs. Lim에게는 24갤런만이 남았습니다. 갤런당 $3.50일 때, 우유 판매 수익은 얼마입니까?

풀이:
1. 오늘 아침 착유량 계산: 68갤런 - 18갤런 = 50갤런
2. 전체 우유량 계산: 어제 아침(68갤런) + 어제 저녁(82갤런) + 오늘 아침(50갤런) = 200갤런
3. 판매한 우유량 계산: 200갤런 - 24갤런(남은 양) = 176갤런
4. 총 수익 계산: $3.50/갤런 × 176갤런 = $616

답: 616
```

#### 📊 평가 지표
| 모델/평가자 | 정확도 |
|------------|--------|
| GPT-3 (175B) | ~35% |
| GPT-3 (6B) | ~20% |
| GPT-3 (3B) | ~15% |

#### ⚠️ 한계점
- 실수로 인한 전체 풀이 과정 실패 가능성

## 4. 감성 지능 평가

### 😊 Ko-EQ-Bench

#### 개요
Ko-EQ-Bench는 대규모 언어 모델(LLM)의 감성 지능(EQ)을 평가하기 위해 설계된 벤치마크입니다. 주로 모델이 복잡한 감정과 사회적 상호작용을 이해하는 능력을 측정하는데 초점을 맞추고 있으며, 대화 속 등장인물의 감정 상태 강도를 예측하게 함으로써 모델의 감정 이해(Emotional Understanding, EU) 능력을 평가합니다. 기본적인 감정 이해력 평가 외에도 창의적 글쓰기 평가와 판단 기반 평가를 선택적으로 실행할 수 있는 옵션을 제공합니다.

#### 주요 특징
- **🎯 객관적 평가**: 평가자의 주관적 해석 없이도 객관적으로 점수 측정 가능
- **🔄 높은 재현성**: 60개(v1) 또는 171개(v2)의 평가 문항으로 반복 가능한 결과 도출 (평균 2.93% CV)
- **📊 뛰어난 변별력**: 다양한 수준의 모델들을 효과적으로 구분 가능
- **🤝 높은 상관관계**: MMLU(r=0.97), HellaSwag(r=0.91), AlpacaEval(r=0.91), MT-bench(r=0.91)와 높은 상관관계
- **⚡ 효율적인 평가**: 10-60분 내에 평가 완료 가능

#### 평가 방식
1. **문항 구성**
   * 감정적 갈등이나 긴장이 있는 대화문 제시
   * 4개의 서로 다른 감정에 대한 강도 평가
   * 각 감정당 0-10 점 척도로 평가

2. **점수 계산 과정**
   * **정규화**: 
     - 응답한 4개의 감정 강도 점수 합이 10이 되도록 정규화
     - 예) 응답: [6, 0, 7, 7] → 정규화: [3, 0, 3.5, 3.5]
   * **차이 계산**: 
     - 정규화된 응답과 참조 답안 간의 절대 차이 합산
   * **문항 점수**: 
     - 10 - (절대 차이들의 합)

3. **벤치마크 최종 점수 산출**
   * **기본 규칙**:
     - 총 문항 중 최소 50개 이상 유효한 답변 필요
     - 50개 미만인 경우 테스트 실패 처리

   * **채점 프로세스**:
     1. 첫 번째 답변 점수 계산
     2. 자체 검토 후 수정된 답변 점수 계산
     3. 두 점수 중 높은 점수를 최종 점수로 채택

#### 예시 문제
```
[대화 시나리오]
Cecilia: 당신의 말은 힘이 있어요, Brandon. 당신이 생각하는 것보다 더요.
Brandon: 잘 알고 있죠, Cecilia. 비평가의 일이 바로 그런 거예요.
Cecilia: 하지만 그 무게를 이해하시나요? 그것이 삶을 산산조각 낼 수 있다는 걸요?
Brandon: 예술은 약한 마음을 위한 것이 아니에요. 비평을 감당할 수 없다면, 
         잘못된 업계에 있는 거죠.
Cecilia: 이건 비평을 감당하는 문제가 아니에요, Brandon. 예술의 영혼을 이해하는 
         문제예요. 당신은 마치 해부대 위의 차갑고 생명 없는 시체처럼 해부하고 있어요.

[평가 과제]
이 대화가 끝난 후, Brandon이 느낄 감정의 강도를 평가하세요:

기분 상한: __/10
공감하는: __/10
자신감 있는: __/10
무시하는: __/10
```

#### 📊 주요 모델별 성능 비교
| 모델 | 점수 |
|------|------|
| GPT-4 (0613) | 62.52 |
| SynthIA-70B | 54.83 |
| GPT-4 (0314) | 53.39 |
| Claude2 | 52.14 |
| Llama-2-70b | 51.56 |
| GPT-3.5 | 49.17 |
| Vicuna-13b | 32.85 |
| Vicuna-7b | 22.24 |

#### ⚠️ 한계점
1. **주관성 문제**
   - 감정 반응 예측의 본질적 주관성 존재
   - 정답 설정의 임의성

2. **측정 한계**
   - 평가 문항 작성자의 능력에 따른 측정 상한선 존재
   - 전문가 검증 부재

3. **문화적 한계**
   - 특정 문화권의 감정 표현 방식에 한정
   - 문화적 맥락의 다양성 반영 부족

4. **기술적 한계**
   - GPT-4로 생성된 대화문 사용으로 인한 잠재적 편향
   - 특정 모델에 유리할 수 있는 가능성

#### 추가 벤치마크 옵션
- **창의적 글쓰기 평가**: 모델의 창의적 글쓰기 능력을 평가하는 선택적 벤치마크
- **판단 기반 평가**: 모델의 판단 능력을 평가하는 추가 벤치마크
